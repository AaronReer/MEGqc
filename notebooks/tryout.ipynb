{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory of the current script\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from meg_qc.calculation.meg_qc_pipeline import make_derivative_meg_qc\n",
    "\n",
    "config_file_path = parent_dir+'/meg_qc/settings/settings.ini' \n",
    "internal_config_file_path=parent_dir+'/meg_qc/settings/settings_internal.ini' # internal settings in in\n",
    "#raw, raw_cropped_filtered_resampled, QC_derivs, QC_simple, df_head_pos, head_pos, scores_muscle_all1, scores_muscle_all2, scores_muscle_all3, raw1, raw2, raw3, avg_ecg, avg_eog = make_derivative_meg_qc(config_file_path, internal_config_file_path)\n",
    "\n",
    "for_report = make_derivative_meg_qc(config_file_path, internal_config_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003483/sub-022/ses-1/meg/sub-022_ses-1_task-deduction_run-1_meg.fif', on_split_missing='ignore')\n",
    "\n",
    "#print(raw.info)\n",
    "print(type(raw.info))\n",
    "\n",
    "#How to extract raw.info from data file, save in derivs and later embed it into the mne report?\n",
    "\n",
    "rep = mne.Report(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from meg_qc.source.universal_plots import make_3d_sensors_trace, keep_unique_locs, switch_names_on_off, QC_derivative\n",
    "from meg_qc.source.initial_meg_qc import MEG_channels\n",
    "\n",
    "\n",
    "def plot_sensors_3d_csv(sensors_csv_path: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Plots the 3D locations of the sensors in the raw file. Plot both mags and grads (if both present) in 1 figure. \n",
    "    Can turn mags/grads visialisation on and off.\n",
    "    Separete channels into brain areas by color coding.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    chs_by_lobe : dict\n",
    "        A dictionary of channels by ch type and lobe.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    qc_derivative : list\n",
    "        A list of QC_derivative objects containing the plotly figures with the sensor locations.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(sensors_csv_path, sep='\\t')\n",
    "\n",
    "\n",
    "    #to not rewrite the whole func, just turn the df back into dic of MEG_channels:\n",
    "\n",
    "    unique_lobes = df['Lobe'].unique().tolist()\n",
    "\n",
    "    lobes_dict={}\n",
    "    for lobe in unique_lobes:\n",
    "        lobes_dict[lobe] = []\n",
    "        for index, row in df.iterrows():\n",
    "            if row['Lobe'] == lobe:\n",
    "                locs = [row[col] for col in df.columns if 'Sensor_location' in col]\n",
    "                lobes_dict[lobe].append(MEG_channels(name = row['Name'], type = row['Type'], lobe = row['Lobe'], lobe_color = row['Lobe Color'], loc = locs))\n",
    "\n",
    "    print(lobes_dict)\n",
    "\n",
    "    traces = []\n",
    "\n",
    "    if len(lobes_dict)>1: #if there are lobes - we use color coding: one color pear each lobe\n",
    "        for lobe in lobes_dict:\n",
    "            ch_locs, ch_names, ch_color, ch_lobe = keep_unique_locs(lobes_dict[lobe])\n",
    "            traces.append(make_3d_sensors_trace(ch_locs, ch_names, ch_color[0], 10, ch_lobe[0], 'circle', 'top left'))\n",
    "            #here color and lobe must be identical for all channels in 1 trace, thi is why we take the first element of the list\n",
    "            # TEXT SIZE set to 10. This works for the \"Always show names\" option but not for \"Show names on hover\" option\n",
    "\n",
    "    else: #if there are no lobes - we use random colors previously assigned to channels, channel names will be used instead of lobe names in make_3d_trace function\n",
    "        ch_locs, ch_names, ch_color, ch_lobe = keep_unique_locs(lobes_dict[lobe])\n",
    "        for i, _ in enumerate(ch_locs):\n",
    "            traces.append(make_3d_sensors_trace([ch_locs[i]], ch_names[i], ch_color[i], 10, ch_names[i], 'circle', 'top left'))\n",
    "\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=900, height=900,\n",
    "        title={\n",
    "        'text': 'Sensors positions',\n",
    "        'y':0.85,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "        xaxis = dict(visible=False),\n",
    "        yaxis = dict(visible=False),\n",
    "        zaxis =dict(visible=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #check_num_channels_correct(chs_by_lobe, 'END_PLOT') #check we didnt change the original dict\n",
    "\n",
    "\n",
    "    # Add the button to have names show up on hover or always:\n",
    "    fig = switch_names_on_off(fig)\n",
    "\n",
    "    fig.update_traces(hoverlabel=dict(font=dict(size=10))) #TEXT SIZE set to 10 again. This works for the \"Show names on hover\" option, but not for \"Always show names\" option\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    qc_derivative = [QC_derivative(content=fig, name='Sensors_positions', content_type='plotly', description_for_user=\"Magnetometers names end with '1' like 'MEG0111'. Gradiometers names end with '2' and '3' like 'MEG0112', 'MEG0113'. \")]\n",
    "\n",
    "    return qc_derivative \n",
    "\n",
    "plot_sensors_3d_csv(sensors_csv_path = '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003483/derivatives/Meg_QC/sub-009/sub-009_ses-1_task-deduction_run-1_desc-Sensors_meg.tsv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})\n",
    "df = df.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row['c1'], row['c2'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotting_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/Paris2020/sub-emptyroom/meg/sub-emptyroom_task-Paris5_meg.fif', allow_maxshield=True)\n",
    "#raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumMD2016/sub-emptyroom/meg/sub-emptyroom_task-Magdeburg2_meg.fif')\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aligned Wave Shapes:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Generate two aligned wave shapes\n",
    "time = np.linspace(0, 1, 100)\n",
    "wave1 = np.sin(2 * np.pi * 2 * time)\n",
    "wave2 = np.sin(2 * np.pi * 2 * time)\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.correlate(wave1, wave2, mode='same')\n",
    "corr1 = pearsonr(wave1, wave2)\n",
    "print(corr1)\n",
    "\n",
    "# Plot the wave shapes and correlation\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, wave1)\n",
    "plt.title('Wave 1')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time, wave2)\n",
    "plt.title('Wave 2')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Misaligned Wave Shapes:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate two misaligned wave shapes\n",
    "time = np.linspace(0, 1, 100)\n",
    "wave1 = np.sin(2 * np.pi * 2 * time)\n",
    "wave2 = np.sin(2 * np.pi * 2 * (time + 0.15))  # Shifted by 0.2 seconds\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.correlate(wave1, wave2, mode='same')\n",
    "corr2 = pearsonr(wave1, wave2)\n",
    "print(corr2)\n",
    "\n",
    "# Plot the wave shapes and correlation\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, wave1)\n",
    "plt.title('Wave 1')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time, wave2)\n",
    "plt.title('Wave 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create wave shapes\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of points in each array\n",
    "num_points = 100\n",
    "\n",
    "# Create an array of time values\n",
    "t = np.linspace(0, 2*np.pi, num_points)\n",
    "\n",
    "# Define the amplitudes for the R-wave shapes\n",
    "amplitudes = [1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
    "\n",
    "# Define the maximum time shift in seconds\n",
    "max_shift = 0.4\n",
    "\n",
    "# Create five arrays with R-wave shapes, shifted in time\n",
    "waves = []\n",
    "for i, amplitude in enumerate(amplitudes):\n",
    "    # Generate a random time shift within the maximum shift range\n",
    "    time_shift = np.random.uniform(-max_shift, max_shift)\n",
    "    \n",
    "    # Shift the time values\n",
    "    shifted_t = t + time_shift\n",
    "    \n",
    "    # Create the R-wave shape with the shifted time values\n",
    "    wave = np.exp(-shifted_t) * np.sin(4*shifted_t) * amplitude\n",
    "    #waves.append(wave)\n",
    "    waves.append(wave[::-1])\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, wave in enumerate(waves):\n",
    "    fig.add_trace(go.Scatter(x=time, y=wave, name=f'Wave {i+1}'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have two arrays: array1 and array2\n",
    "array1 = waves[0]\n",
    "array2 = waves[5]\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Assuming you have two arrays: array1 and array2\n",
    "\n",
    "# Find peaks in both arrays\n",
    "peaks1, _ = find_peaks(array1)\n",
    "peaks2, _ = find_peaks(array2)\n",
    "\n",
    "# Calculate the time shift based on the peak positions\n",
    "time_shift = peaks1[0] - peaks2[0]\n",
    "\n",
    "# Shift array2 to align with array1\n",
    "aligned_array2 = np.roll(array2, time_shift)\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the array1 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array1)), y=array1, name='Array 1'))\n",
    "\n",
    "# Add the array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array2)), y=array2, name='Array 2'))\n",
    "\n",
    "# Add the aligned_array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(aligned_array2)), y=aligned_array2, name='Aligned Array 2'))\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(title='Aligned Arrays using Peak Detection',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='Amplitude')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "array1 = waves[0]\n",
    "array2 = -waves[5]\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the array1 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array1)), y=array1, name='Array 1'))\n",
    "\n",
    "# Add the array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array2)), y=array2, name='Array 2'))\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(title='Aligned Arrays using Peak Detection',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='Amplitude')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming you have two arrays: array1 and array2\n",
    "\n",
    "# Find peaks in array1\n",
    "peaks1, _ = find_peaks(array1)\n",
    "\n",
    "# Initialize variables for best alignment\n",
    "best_time_shift = 0\n",
    "best_correlation = -np.inf\n",
    "best_aligned_array2 = None\n",
    "\n",
    "# Try aligning array2 in both orientations\n",
    "for flip in [False, True]:\n",
    "    # Flip array2 if needed\n",
    "    #aligned_array2 = np.flip(array2) if flip else array2\n",
    "    aligned_array2 = -array2 if flip else array2\n",
    "\n",
    "    # Find peaks in aligned_array2\n",
    "    peaks2, _ = find_peaks(aligned_array2)\n",
    "\n",
    "    # Calculate the time shift based on the peak positions\n",
    "    time_shift = peaks1[0] - peaks2[0]\n",
    "\n",
    "    # Shift aligned_array2 to align with array1\n",
    "    aligned_array2 = np.roll(aligned_array2, time_shift)\n",
    "\n",
    "    # Calculate the correlation between array1 and aligned_array2\n",
    "    correlation = np.corrcoef(array1, aligned_array2)[0, 1]\n",
    "\n",
    "    # Update the best alignment if the correlation is higher\n",
    "    if correlation > best_correlation:\n",
    "        best_correlation = correlation\n",
    "        best_time_shift = time_shift\n",
    "        best_aligned_array2 = aligned_array2\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the array1 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array1)), y=array1, name='Array 1'))\n",
    "\n",
    "# Add the array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array2)), y=array2, name='Array 2'))\n",
    "\n",
    "# Add the best_aligned_array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(best_aligned_array2)), y=best_aligned_array2, name='Aligned Array 2'))\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(title='Aligned Arrays with Flipped Second Array',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='Amplitude')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "avg_ecg_epoch_data_nonflipped_limited_to_event = np.array(waves)\n",
    "\n",
    "max_values=np.max(np.abs(avg_ecg_epoch_data_nonflipped_limited_to_event), axis=1)\n",
    "print(max_values)\n",
    "max_values_ind=np.argsort(max_values)[::-1] \n",
    "print(max_values_ind)\n",
    "max_values_ind=max_values_ind[:5]\n",
    "\n",
    "chosen_5 = (avg_ecg_epoch_data_nonflipped_limited_to_event[max_values_ind])\n",
    "\n",
    "thresh_lvl_peakfinder = 5\n",
    "\n",
    "\n",
    "#get the highest peak for every channel:\n",
    "max_amplitude1 = []\n",
    "index_of_max_amplitude1=[]\n",
    "for ch_data in avg_ecg_epoch_data_nonflipped_limited_to_event:\n",
    "\n",
    "    thresh_mean=(max(ch_data) - min(ch_data)) / thresh_lvl_peakfinder\n",
    "    peak_locs_pos, _ = find_peaks(ch_data, prominence=thresh_mean)\n",
    "    peak_locs_neg, _ = find_peaks(-ch_data, prominence=thresh_mean)\n",
    "\n",
    "    all_peaks = np.concatenate((peak_locs_pos, peak_locs_neg))\n",
    "    print('all peaks', all_peaks)\n",
    "\n",
    "    #Find the peak with the maximal amplitude:\n",
    "\n",
    "    max_amplitude_peak = np.argmax(np.abs(ch_data[all_peaks]))\n",
    "\n",
    "    #now find the index of this point in the channel data:\n",
    "    index_of_max_amplitude1.append(all_peaks[max_amplitude_peak])\n",
    "\n",
    "    print('Index1', index_of_max_amplitude1)\n",
    "\n",
    "    #now find the magnitude of the data in this point:\n",
    "\n",
    "    max_amplitude1.append(ch_data[index_of_max_amplitude1[-1]])\n",
    "\n",
    "    \n",
    "\n",
    "# find 5 channels which have the highest peaks and get the locations of these peaks:\n",
    "highest_channels_sorted = np.argsort(max_amplitude1)[::-1] \n",
    "print(highest_channels_sorted)\n",
    "max_ind_of_chosen_5=highest_channels_sorted[:5]\n",
    "\n",
    "print(max_ind_of_chosen_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_max_amplitude2=[]\n",
    "for ch_data in max_ind_of_chosen_5:\n",
    "\n",
    "    thresh_mean=(max(ch_data) - min(ch_data)) / thresh_lvl_peakfinder\n",
    "    peak_locs_pos, _ = find_peaks(ch_data, prominence=thresh_mean)\n",
    "    peak_locs_neg, _ = find_peaks(-ch_data, prominence=thresh_mean)\n",
    "\n",
    "    all_peaks = np.concatenate((peak_locs_pos, peak_locs_neg))\n",
    "    print('all peaks', all_peaks)\n",
    "\n",
    "    #Find the peak with the maximal amplitude:\n",
    "\n",
    "    max_amplitude_peak = np.argmax(np.abs(ch_data[all_peaks]))\n",
    "\n",
    "\n",
    "    #6. Output the index of the point with the maximal amplitude:\n",
    "\n",
    "    index_of_max_amplitude1.append(all_peaks[max_amplitude_peak])\n",
    "    print('Index1', index_of_max_amplitude1)\n",
    "\n",
    "    if len(all_peaks)>1:\n",
    "        #7. Now find the second largest peak:\n",
    "        all_peaks_without_max = np.delete(all_peaks, max_amplitude_peak)\n",
    "\n",
    "        print('no max', all_peaks_without_max)\n",
    "\n",
    "        max_amplitude_peak = np.argmax(np.abs(ch_data[all_peaks_without_max]))\n",
    "\n",
    "\n",
    "        #6. Output the index of the point with the maximal amplitude:\n",
    "\n",
    "        index_of_max_amplitude2.append(all_peaks_without_max[max_amplitude_peak])\n",
    "        print('Index2', index_of_max_amplitude2)\n",
    "        \n",
    "    else:\n",
    "        index_of_max_amplitude2.append(np.nan)\n",
    "\n",
    "mean_index_of_max_amplitude1 = np.nanmean(index_of_max_amplitude1)\n",
    "\n",
    "# If in more than a half of cases there was no second biggest peak found, skip it and assign t) as first peak:\n",
    "non_zero_count = np.count_nonzero(index_of_max_amplitude2)\n",
    "percentage = (non_zero_count/len(index_of_max_amplitude2)) * 100\n",
    "\n",
    "if percentage < 50:\n",
    "    t0_peak = int(mean_index_of_max_amplitude1)\n",
    "else:\n",
    "    mean_index_of_max_amplitude2 = np.nanmean(index_of_max_amplitude2)\n",
    "    #Now out of them set the first peak (according to time) as t0.\n",
    "    t0_peak = int(np.nanmin([mean_index_of_max_amplitude1, mean_index_of_max_amplitude2]))\n",
    "\n",
    "\n",
    "print('mean_ind1', mean_index_of_max_amplitude1)\n",
    "print('mean_ind2', mean_index_of_max_amplitude2)\n",
    "\n",
    "\n",
    "print(t0_peak)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([5, 2, 9, 1, 7, 3])\n",
    "\n",
    "# Get the indices that would sort the array in ascending order\n",
    "sorted_indices = np.argsort(arr)\n",
    "\n",
    "# Index of the largest value\n",
    "largest_index = sorted_indices[-1]\n",
    "\n",
    "# Index of the second largest value\n",
    "second_largest_index = sorted_indices[-2]\n",
    "\n",
    "print(\"Index of the largest value:\", largest_index)\n",
    "print(\"Index of the second largest value:\", second_largest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the MEG data\n",
    "raw=mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif', preload=True)\n",
    "\n",
    "display(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the EOG channel names\n",
    "eog_channels = ['EOG 061', 'EOG 062']\n",
    "\n",
    "# extract the data of 2 EOG channels\n",
    "eog_data = raw.copy().pick_channels(eog_channels).get_data()\n",
    "\n",
    "print(eog_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data with plotly:\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "x_values = raw.times\n",
    "\n",
    "# Add a trace for the first subplot\n",
    "fig.add_trace(go.Scatter(x=x_values, y=eog_data[0], mode='lines', name='EOG 1'), row=1, col=1)\n",
    "\n",
    "# Add a trace for the second subplot\n",
    "fig.add_trace(go.Scatter(x=x_values, y=eog_data[1], mode='lines', name='EOG 2'), row=2, col=1)\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(title='EOG Data', xaxis_title='Time (s)', yaxis_title='Amplitude')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create two arrays\n",
    "array1 = np.array([1, 2, 3, 4, 5])\n",
    "array2 = np.array([6, 7, 8, 9, 10])\n",
    "\n",
    "# stack the arrays horizontally\n",
    "stacked = np.stack((array1, array2), axis=0)\n",
    "\n",
    "display(stacked)\n",
    "\n",
    "# calculate the covariance matrix\n",
    "covariance_matrix = np.cov(stacked)\n",
    "\n",
    "print(covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Load the MEG data\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003703/sub-a68d5xp5/meg/sub-a68d5xp5_task-listeningToSpeech_run-01_meg.fif')\n",
    "#raw=mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif', preload=True)\n",
    "\n",
    "# Select the EOG channels\n",
    "eog_channels = mne.pick_types(raw.info, meg=False, eeg=False, stim=False, eog=True)\n",
    "\n",
    "# Get the names of the EOG channels\n",
    "eog_channel_names = [raw.ch_names[ch] for ch in eog_channels]\n",
    "\n",
    "print('EOG channel names:', eog_channel_names)\n",
    "\n",
    "eog_events = mne.preprocessing.find_eog_events(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "picks_ECG = mne.pick_types(raw.info, ecg=True)\n",
    "ecg_ch_name = [raw.info['chs'][name]['ch_name'] for name in picks_ECG]\n",
    "\n",
    "arr=raw.get_data(picks=ecg_ch_name)[0] \n",
    "height = np.mean(arr) + 1 * np.std(arr)\n",
    "fs=raw.info['sfreq']\n",
    "peaks, _ = find_peaks(arr, height=height, distance=round(0.5 * fs)) #assume there are no peaks within 0.5 seconds from each other.\n",
    "ecg_events = peaks/fs\n",
    "\n",
    "# Define the time window of interest\n",
    "time_window = [0.2, 0.2]  # in seconds\n",
    "tmin=-0.2\n",
    "tmax=0.2\n",
    "\n",
    "# Convert time window to samples\n",
    "sfreq = 1000  # sampling frequency of your data\n",
    "time_window_samples = np.round(np.array(time_window) * sfreq).astype(int)\n",
    "print('samples', time_window_samples)\n",
    "\n",
    "# Initialize an empty array to store the extracted epochs\n",
    "epochs = np.zeros((len(peaks), int((tmax-tmin)*sfreq)))\n",
    "\n",
    "print('HERE')\n",
    "print(arr)\n",
    "print(epochs)\n",
    "\n",
    "# Loop through each ECG event and extract the corresponding epoch\n",
    "for i, event in enumerate(peaks):\n",
    "    start = event - time_window_samples[0]\n",
    "    start = np.round(event + tmin*sfreq).astype(int)\n",
    "    end = event + time_window_samples[1]\n",
    "    end= np.round(event + tmax*sfreq).astype(int)\n",
    "    epochs[i, :] = arr[start:end]\n",
    "\n",
    "#average all epochs:\n",
    "avg_ecg=np.mean(epochs, axis=0)\n",
    "\n",
    "#print average ecg with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "#create time vector based on time window and sampling frequency:\n",
    "times= np.arange(tmin, tmax, 1/sfreq)\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_ecg, mode='lines', name='ECG'))\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detect the R-wave peaks in the filtered ECG channel data\n",
    "r_peaks, ch_ecg, pulse, ecg_data_rec = mne.preprocessing.find_ecg_events(raw, return_ecg=True)\n",
    "print(ecg_data_rec)\n",
    "\n",
    "#plot the ECG data with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "times=[t for t in range(len(ecg_data_rec[0]))]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=times, y=ecg_data_rec[0], mode='lines', name='ECG'))\n",
    "fig.update_layout(title='ECG data', xaxis_title='Time (s)', yaxis_title='ECG (mV)')\n",
    "fig.show()\n",
    "\n",
    "# Calculate the time difference between each R-wave peak and the first R-wave peak\n",
    "r_wave_epochs = (r_peaks - r_peaks[0]) / raw.info['sfreq']\n",
    "print('r_wave_epochs', r_wave_epochs)\n",
    "\n",
    "# Calculate the average R-wave epoch\n",
    "avg_r_wave_epoch = np.mean(r_wave_epochs)\n",
    "print('avg_r_wave_epoch', avg_r_wave_epoch)\n",
    "\n",
    "if ecg_ch_name:\n",
    "    # Extract the ECG channel data\n",
    "    ecg_data, times = raw.get_data(ecg_ch_name, return_times=True)\n",
    "    ecg_data2=ecg_data_rec\n",
    "else:\n",
    "    ecg_data=ecg_data_rec\n",
    "\n",
    "\n",
    "\n",
    "# Use the average R-wave epoch to extract a segment of data from the ECG channel\n",
    "avg_r_wave_data = ecg_data[:, int(avg_r_wave_epoch * raw.info['sfreq']) : int((avg_r_wave_epoch + 0.2) * raw.info['sfreq'])]\n",
    "avg_r_wave_data2 = ecg_data2[:, int(avg_r_wave_epoch * raw.info['sfreq']) : int((avg_r_wave_epoch + 0.2) * raw.info['sfreq'])]\n",
    "\n",
    "#plot the average R-wave epoch with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "times=[t/raw.info['sfreq'] for t in range(len(avg_r_wave_data[0]))]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_r_wave_data[0], mode='lines', name='ECG'))\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_r_wave_data2[0], mode='lines', name='ECG2'))\n",
    "fig.update_layout(title='Average R-wave epoch', xaxis_title='Time (s)', yaxis_title='ECG (mV)')\n",
    "fig.show()\n",
    "\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([t/raw.info['sfreq'] for t in range(len(avg_r_wave_data[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data\n",
    "avg_r_wave_epoch * raw.info['sfreq']\n",
    "r_peaks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_r_wave_data = ecg_data[:, int(avg_r_wave_epoch * raw.info['sfreq']) : int((avg_r_wave_epoch + 0.2) * raw.info['sfreq'])]\n",
    "avg_r_wave_data2 = ecg_data2[:, int(avg_r_wave_epoch * raw.info['sfreq']) : int((avg_r_wave_epoch + 0.2) * raw.info['sfreq'])]\n",
    "\n",
    "#plot the average R-wave epoch with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "times=[t/raw.info['sfreq'] for t in range(len(avg_r_wave_data[0]))]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_r_wave_data[0], mode='lines', name='ECG'))\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_r_wave_data2[0], mode='lines', name='ECG2'))\n",
    "fig.update_layout(title='Average R-wave epoch', xaxis_title='Time (s)', yaxis_title='ECG (mV)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Generate two waves\n",
    "wave1 = np.array([1, 2, 3, 4, 5])\n",
    "wave2 = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Calculate the Pearson correlation coefficient and p-value\n",
    "corr_coef, p_value = pearsonr(wave1, wave2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Pearson correlation coefficient:\", corr_coef)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "\n",
    "#plot both waves with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=wave1, mode='lines', name='wave1'))\n",
    "fig.add_trace(go.Scatter(y=wave2, mode='lines', name='wave2'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "lobe_colors = {\n",
    "        'Left Frontal': '#1f77b4',\n",
    "        'Right Frontal': '#ff7f0e',\n",
    "        'Left Temporal': '#2ca02c',\n",
    "        'Right Temporal': '#9467bd',\n",
    "        'Left Parietal': '#e377c2',\n",
    "        'Right Parietal': '#d62728',\n",
    "        'Left Occipital': '#bcbd22',\n",
    "        'Right Occipital': '#17becf'}\n",
    "\n",
    "print(random.choice(list(lobe_colors.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "\n",
    "# Generate some noisy wave data\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(x) + np.random.normal(0, 0.5, 100)\n",
    "\n",
    "# Apply Gaussian smoothing with a sigma of 2\n",
    "y_smooth = gaussian_filter(y, sigma=4)\n",
    "\n",
    "# Plot the original and smoothed waves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y, label='Noisy wave')\n",
    "plt.plot(x, y_smooth, label='Smoothed wave')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "# create sample data\n",
    "df = pd.DataFrame({'values': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, index=['A']*10)\n",
    "df = df.T\n",
    "print(df)\n",
    "\n",
    "# create box plot trace\n",
    "box_trace = go.Box(x=df.iloc[0], orientation='h')\n",
    "#box_trace = go.Box(x=df['values'], y=df.index, orientation='h', name='')\n",
    "\n",
    "fig = go.Figure(data=box_trace)\n",
    "\n",
    "for col in df.columns:\n",
    "    fig.add_trace(go.Scatter(x=df[col], name=col))\n",
    "\n",
    "# for v in df['values']:\n",
    "#     #fig.add_trace(go.Scatter(x=df['values'], y=df.index, mode='markers', marker=dict(size=5, color='yellow'), name='Scatter Plot', hovertext=df.index))\n",
    "#     fig.add_trace(go.Scatter(x=[v], y=['A'], mode='markers', marker=dict(size=5, color='yellow'), name='Scatter Plot', hovertext=df.index))\n",
    "\n",
    "# plot figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add box plot trace\n",
    "fig.add_trace(go.Box(x=[1, 2, 3, 4, 5]))\n",
    "\n",
    "# Add horizontal line at y=0\n",
    "fig.update_layout(\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type='line',\n",
    "            yref='y',\n",
    "            y0=0,\n",
    "            y1=0,\n",
    "            xref='paper',\n",
    "            x0=0,\n",
    "            x1=1\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create example dataset\n",
    "np.random.seed(123)\n",
    "std_val = pd.DataFrame({'Group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "                     'Value': np.random.normal(size=6)})\n",
    "\n",
    "# Create box plot with custom marker colors\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(x=std_val['Group'], y=std_val['Value'], name='Value',\n",
    "                     marker=dict(color='red')))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Box plot with custom marker colors',\n",
    "                  xaxis_title='Group', yaxis_title='Value')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "# create a box plot with custom marker color\n",
    "trace = go.Box(\n",
    "    y=[1, 2, 3, 4, 5],\n",
    "    marker=dict(\n",
    "        color='blue'\n",
    "    )\n",
    ")\n",
    "\n",
    "# create a figure and add the box plot trace\n",
    "fig = go.Figure(data=[trace])\n",
    "\n",
    "# show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This here is to save all the average ECG/EOG data into a pickle file, so I can test difefrent wave detection algorythms on them without running the pipeline again\n",
    "\n",
    "import pickle \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# open a file in write binary mode\n",
    "with open(\"avg_ecg.pkl\", \"wb\") as f:\n",
    "    # dump the list of objects into the file\n",
    "    pickle.dump(avg_ecg, f)\n",
    "\n",
    "with open(\"avg_eog.pkl\", \"wb\") as f:\n",
    "    # dump the list of objects into the file\n",
    "    pickle.dump(avg_eog, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This here is to open the pickle files from above and plot the data\n",
    "\n",
    "import pickle \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# open the file in read binary mode\n",
    "with open(\"avg_ecg0.pkl\", \"rb\") as f:\n",
    "    # load the list of objects from the file\n",
    "    eog_list = pickle.load(f)\n",
    "\n",
    "print(eog_list[0])\n",
    "\n",
    "sfreq=1000\n",
    "t = np.round(np.arange(-0.4, 0.4+1/sfreq, 1/sfreq), 3) #yes, you need to round\n",
    "fig0=go.Figure()\n",
    "for x in range(0, len(eog_list)):\n",
    "    fig_temp=eog_list[x].plot_epoch_and_peak(t, 'Channels affected by ECG artifact: ', 'mag', fig0)\n",
    "    for trace in fig_temp['data']:\n",
    "        fig0.add_trace(trace)\n",
    "\n",
    "fig0.update_layout(\n",
    "    yaxis = dict(\n",
    "            showexponent = 'all',\n",
    "            exponentformat = 'e')) \n",
    "fig0.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for EOG\n",
    "\n",
    "import pickle \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "# open the file in read binary mode\n",
    "with open(\"avg_eog0.pkl\", \"rb\") as f:\n",
    "    # load the list of objects from the file\n",
    "    eog_list = pickle.load(f)\n",
    "\n",
    "sfreq=1000\n",
    "t = np.round(np.arange(-0.4, 0.4+1/sfreq, 1/sfreq), 3) #yes, you need to round\n",
    "fig0=go.Figure()\n",
    "for x in range(0, len(eog_list)):\n",
    "    fig_temp=eog_list[x].plot_epoch_and_peak(t, 'Channels affected by ECG artifact: ', 'mag')\n",
    "    for trace in fig_temp['data']:\n",
    "        fig0.add_trace(trace)\n",
    "\n",
    "fig0.update_layout(\n",
    "    yaxis = dict(\n",
    "            showexponent = 'all',\n",
    "            exponentformat = 'e')) \n",
    "fig0.show()\n",
    "\n",
    "#Now apply the gaussia filter to each trace and plot result in the same figure:\n",
    "fig0_new=deepcopy(fig0)\n",
    "for trace in fig0_new['data']:\n",
    "    y=trace['y']\n",
    "    y_smooth = gaussian_filter(y, sigma=10)\n",
    "    trace['y']=y_smooth\n",
    "\n",
    "fig0_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show sensor posiions using mne:\n",
    "\n",
    "import mne\n",
    "\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)\n",
    "\n",
    "mne.viz.plot_sensors(raw.info, kind='topomap', ch_type='grad', show_names=True, ch_groups='position')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT SENSORS IN 2D with plotly\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import mne\n",
    "\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)\n",
    "\n",
    "\n",
    "mag_ch_names = raw.copy().pick_types(meg='mag').ch_names if 'mag' in raw else None\n",
    "grad_ch_names = raw.copy().pick_types(meg='grad').ch_names if 'grad' in raw else None\n",
    "channels_objs = {'mag': mag_ch_names, 'grad': grad_ch_names}\n",
    "\n",
    "# Get the sensor locations\n",
    "sensor_locs = raw.info['chs']\n",
    "#print(sensor_locs)\n",
    "#coords_mag=[loc['loc'][:2] for loc in sensor_locs]\n",
    "coords_mag=[loc['loc'] for loc in sensor_locs if loc['ch_name'] in mag_ch_names]\n",
    "#print(len(coords), coords)\n",
    "print(len(coords_mag), coords_mag)\n",
    "\n",
    "x = [r[0] for r in coords_mag]\n",
    "y = [r[1] for r in coords_mag]\n",
    "#x, y, z = [loc['loc'][:3] for loc in sensor_locs]\n",
    "names = [loc['ch_name'] for loc in sensor_locs if loc['ch_name'] in mag_ch_names]\n",
    "kinds= [loc['kind'] for loc in sensor_locs]\n",
    "print(kinds)\n",
    "\n",
    "# Create a scatter plot of the sensor locations\n",
    "fig = go.Figure(data=go.Scatter(x=x, y=y, mode='markers', text=names))\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=1000)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "fig.update_layout(title='MEG Sensor Locations', xaxis_title='X', yaxis_title='Y')\n",
    "\n",
    "# Add a circle shape to the plot to show the position of the head\n",
    "fig.update_layout(\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type='circle',\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            x0=-0.1,\n",
    "            y0=-0.1,\n",
    "            x1=0.1,\n",
    "            y1=0.12,\n",
    "            line=dict(color='red', width=2),\n",
    "            opacity=0.5\n",
    "        ),\n",
    "        dict(\n",
    "            type='line',\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            x0=[0, -0.02],\n",
    "            y0=[0.1, 0.08],\n",
    "            line=dict(color='black', width=2)\n",
    "        ),\n",
    "        dict(\n",
    "            type='line',\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            x0=[0, 0.02],\n",
    "            y0=[0.1, 0.08],\n",
    "            line=dict(color='black', width=2)\n",
    "        ),\n",
    "        dict(\n",
    "            type='line',\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            x0=[-0.02, 0.02],\n",
    "            y0=[0.08, 0.08],\n",
    "            line=dict(color='black', width=2))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Show the plot \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)\n",
    "\n",
    "#PLOT 3 D\n",
    "\n",
    "def switch_names_on_off(fig):\n",
    "    # Define the buttons\n",
    "    buttons = [\n",
    "    dict(label='Show channel names when hovering',\n",
    "         method='update',\n",
    "         args=[{'mode': 'markers'}]),\n",
    "    dict(label='Always show channel names',\n",
    "         method='update',\n",
    "         args=[{'mode': 'markers+text'}])\n",
    "    ]\n",
    "\n",
    "    # Add the buttons to the layout\n",
    "    fig.update_layout(updatemenus=[dict(type='buttons',\n",
    "                                        showactive=True,\n",
    "                                        buttons=buttons)])\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# Extract the sensor locations and names for magnetometers\n",
    "mag_locs = raw.copy().pick_types(meg='mag').info['chs']\n",
    "mag_pos = [ch['loc'][:3] for ch in mag_locs]\n",
    "mag_names = [ch['ch_name'] for ch in mag_locs]\n",
    "\n",
    "# Create the magnetometer plot with markers only\n",
    "\n",
    "mag_fig = go.Figure(data=[go.Scatter3d(x=[pos[0] for pos in mag_pos],\n",
    "                                       y=[pos[1] for pos in mag_pos],\n",
    "                                       z=[pos[2] for pos in mag_pos],\n",
    "                                       mode='markers',\n",
    "                                       marker=dict(size=5),\n",
    "                                       text=mag_names,\n",
    "                                       hovertemplate='%{text}')],\n",
    "                                       layout=go.Layout(width=1000, height=1000))\n",
    "\n",
    "mag_fig.update_layout(title='Magnetometers')\n",
    "\n",
    "mag_fig = switch_names_on_off(mag_fig)\n",
    "mag_fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# Extract the sensor locations and names for gradiometers\n",
    "grad_locs = raw.copy().pick_types(meg='grad').info['chs']\n",
    "grad_pos = [ch['loc'][:3] for ch in grad_locs]\n",
    "grad_names = [ch['ch_name'] for ch in grad_locs]\n",
    "\n",
    "#since grads have 2 sensors located in the same spot - need to put their names together to make pretty plot labels:\n",
    "\n",
    "grad_pos_together = []\n",
    "grad_names_together = []\n",
    "\n",
    "for i in range(len(grad_pos)-1):\n",
    "    if all(x == y for x, y in zip(grad_pos[i], grad_pos[i+1])):\n",
    "        grad_pos_together += [grad_pos[i]]\n",
    "        grad_names_together += [grad_names[i]+', '+grad_names[i+1]]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Add both sets of gradiometer positions to the plot:\n",
    "grad_fig = go.Figure(data=[go.Scatter3d(x=[pos[0] for pos in grad_pos_together],\n",
    "                                        y=[pos[1] for pos in grad_pos_together],\n",
    "                                        z=[pos[2] for pos in grad_pos_together],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(size=5),\n",
    "                                        text=grad_names_together,\n",
    "                                        hovertemplate='%{text}')],\n",
    "                                        layout=go.Layout(width=1000, height=1000))\n",
    "\n",
    "grad_fig.update_layout(title='Gradiometers')\n",
    "\n",
    "\n",
    "# Add the button to have names show up on hover or always:\n",
    "grad_fig = switch_names_on_off(grad_fig)\n",
    "\n",
    "# Show the plots\n",
    "\n",
    "grad_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MUSCLE ARIFACTS IN EMPTYROOM DATA:\n",
    "# Discussed with Andreas:\n",
    "# We can see very high muscle scores at the very beginning and end of the empty room recording\n",
    "# Are these real muscle artifacts or filtering errors?\n",
    "# Cut out 1st second of the data where they are visible.\n",
    "# make Fourier transform of the 1st second and see if there are high amplitudes visible for the muscle frequencies - nope \n",
    "# most likely this is filtering.\n",
    "# next, follow the MNE steps for muscle artifact detection: they use first filtering at 11--140 hz, then Hilbert\n",
    "# plotted raw data after the applied filter, and Hilbert - see cut artifacts in the beginning and end. (WJY arw we sure it  s not hilbert?)\n",
    "# then, tried to only filter - very noisy data. but most likely the filtering is the source. Because of the cut-off in the beginning and end.\n",
    "# Solutions: zero padding in the beginning and end before filtering, which will be cut off after. But may still create a jump while filtering and keep the artifact.\n",
    "# Better: add 2s of dummy data at the beginning and end of the recording, and then crop it out (the data added should be mirrored). This will not create a jump in the filtering.\n",
    "# Tried\n",
    "\n",
    "# Problem found! 2 problems: \n",
    "# 1st: The main artifact is actually introduced by filtering power lines. filtering the data at 150 Hz (harmonics) clearly creates this artifact.\n",
    "# Removed that and any other filtering over the range of muscle freqs, since we don't need them anyways. (over 140 Hz)\n",
    "# 2nd: Still some artifact is present in the beginning and end of the recording. For this attach mirrored data on both ends.\n",
    "# Then detect muscle, then cut the resulting scores away for the attached period.\n",
    "# There will be still some very minimal artifact at the beginning/end of this attachment - probably due to the attachment itself: the mirrored data is still not a normally shaped signal.\n",
    "# See example in cell above of how all 3 option look: oroginal, with attached data and with attached and cut away.\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import mne\n",
    "\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)\n",
    "\n",
    "#%matplotlib qt\n",
    "raw_first = raw.copy().crop(tmin=0, tmax=1)\n",
    "#raw_first.plot()\n",
    "\n",
    "\n",
    "std_val=raw_first.get_data()\n",
    "\n",
    "window = np.hanning(std_val.shape[-1])*std_val\n",
    "\n",
    "window\n",
    "\n",
    "freqs = np.fft.rfftfreq(window.shape[-1], 1/raw.info['sfreq'])\n",
    "\n",
    "components = np.fft.fft(window, axis=-1)\n",
    "\n",
    "components.shape\n",
    "\n",
    "fig = go.Figure()\n",
    "for ch in range(15, 250):\n",
    "    fig.add_trace(go.Scatter(x=freqs, y = np.abs(components[ch, 0:500])))\n",
    "fig.add_trace(go.Scatter(x=freqs, y = np.abs(components[0, 0:500])))\n",
    "#from mne annotate_muscle_zscore:\n",
    "from scipy.stats import zscore\n",
    "from scipy.ndimage import label\n",
    "\n",
    "filter_freq=(110, 140)\n",
    "legend_category = 'mag'\n",
    "\n",
    "raw_copy = raw_first.copy()\n",
    "raw_copy.load_data()\n",
    "\n",
    "if legend_category is None:\n",
    "    raw_ch_type = raw_copy.get_channel_types()\n",
    "    if 'mag' in raw_ch_type:\n",
    "        legend_category = 'mag'\n",
    "    elif 'grad' in raw_ch_type:\n",
    "        legend_category = 'grad'\n",
    "    elif 'eeg' in raw_ch_type:\n",
    "        legend_category = 'eeg'\n",
    "    else:\n",
    "        raise ValueError('No M/EEG channel types found, please specify a'\n",
    "                            ' ch_type or provide M/EEG sensor data')\n",
    "\n",
    "if legend_category in ('mag', 'grad'):\n",
    "    raw_copy.pick_types(meg=legend_category, ref_meg=False)\n",
    "else:\n",
    "    legend_category = {'meg': False, legend_category: True}\n",
    "    raw_copy.pick_types(**legend_category)\n",
    "\n",
    "#raw_copy.filter(filter_freq[0], filter_freq[1], fir_design='firwin',\n",
    "#                pad=\"reflect_limited\")\n",
    "\n",
    "hilb_applied=raw_copy.apply_hilbert(envelope=True)\n",
    "hilb_applied.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the list of values into a NumPy array\n",
    "values = np.array([1, 2, 1.8, 2.5, 3, 3.5, 4, 3.8, 5, 4, 2, 2.1, 1, 0, 2, 4, 6])\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, savgol_filter, find_peaks\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Generate a noisy wave shape\n",
    "t = np.linspace(0, 10, 1000)\n",
    "y = np.sin(t) + 0.5*np.random.randn(len(t))\n",
    "\n",
    "data = np.random.randn(1000) #no wave shape\n",
    "# Load the noisy wave data into a NumPy array\n",
    "wave_data = data\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t, y=wave_data, mode='lines', name='Noisy Wave'))\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Amplitude', title='Noisy Wave Shape')\n",
    "fig.show()\n",
    "\n",
    "# Apply a low-pass filter to remove high-frequency noise\n",
    "b, a = butter(5, 0.1, 'low')\n",
    "filtered_data = filtfilt(b, a, wave_data)\n",
    "\n",
    "# plot filtered data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t, y=filtered_data, mode='lines', name='Filtered Wave'))\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Amplitude', title='Filtered Wave Shape')\n",
    "fig.show()\n",
    "\n",
    "# Apply a Savitzky-Golay filter to further reduce noise and extract the underlying wave shape\n",
    "#smoothed_data = savgol_filter(wave_data, window_length=int(len(wave_data)/4), polyorder=3)\n",
    "smoothed_data = savgol_filter(data, window_length=100, polyorder=3)\n",
    "\n",
    "# Identify the shape of the wave using peak detection or curve fitting\n",
    "# For example, you can use the `scipy.signal.find_peaks` function to detect peaks in the smoothed data\n",
    "#peaks, _ = find_peaks(smoothed_data, height=0.5*np.max(smoothed_data))\n",
    "peaks, _ = find_peaks(smoothed_data)\n",
    "\n",
    "# plot smoothed data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t, y=smoothed_data, mode='lines', name='Smoothed Wave'))\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Amplitude', title='Smoothed Wave Shape')\n",
    "fig.add_trace(go.Scatter(x=t[peaks], y=smoothed_data[peaks], mode='markers', name='Peaks'))\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Generate a noisy wave shape\n",
    "t = np.linspace(0, 10, 1000)\n",
    "y = np.sin(t) + 0.5*np.random.randn(len(t))\n",
    "\n",
    "# Find the peaks in the wave\n",
    "peaks, _ = find_peaks(y)\n",
    "\n",
    "# Count the number of peaks\n",
    "num_peaks = len(peaks)\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the noisy wave shape to the figure\n",
    "fig.add_trace(go.Scatter(x=t, y=y, mode='lines', name='Noisy Wave'))\n",
    "\n",
    "# Add the peaks to the figure\n",
    "fig.add_trace(go.Scatter(x=t[peaks], y=y[peaks], mode='markers', name='Peaks'))\n",
    "\n",
    "# Add axis labels and a title\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Amplitude', title='Noisy Wave Shape')\n",
    "\n",
    "# Show the figure and print the number of peaks\n",
    "fig.show()\n",
    "print(f'The wave has {num_peaks} crest(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "picks_EOG = mne.pick_types(raw.info, eog=True)\n",
    "eog_ch_name = [raw.info['chs'][name]['ch_name'] for name in picks_EOG]\n",
    "eog_ch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_psd = [2.93686870e-12, 5.37336497e-13, 2.34749324e-13, 1.70403629e-13\n",
    ", 1.42868936e-13, 1.10614848e-13, 1.01586902e-13, 9.41699507e-14\n",
    ", 8.41904711e-14, 7.56254639e-14, 6.98933286e-14, 6.47116338e-14\n",
    ", 5.37107007e-14, 5.42174045e-14, 4.78692577e-14, 4.36476164e-14\n",
    ", 3.69272073e-14, 3.81479068e-14, 4.07614720e-14, 3.71683505e-14\n",
    ", 3.74843265e-14, 3.57210926e-14, 3.99173535e-14, 4.87143053e-14\n",
    ", 4.20066645e-14, 3.84896719e-14, 3.13482998e-14, 2.86289627e-14\n",
    ", 2.82586165e-14, 2.71780036e-14, 2.48692250e-14, 2.71251350e-14\n",
    ", 2.79561808e-14, 2.72047767e-14, 2.79637330e-14, 2.55955578e-14\n",
    ", 2.53291180e-14, 2.01500680e-14, 2.12080778e-14, 2.18529602e-14\n",
    ", 2.12775368e-14, 2.14334140e-14, 2.18751322e-14, 1.97884378e-14\n",
    ", 1.89952388e-14, 1.79404586e-14, 2.01555022e-14, 2.21105500e-14\n",
    ", 1.87897255e-14, 1.95585625e-14, 2.07067862e-14, 2.15786185e-14\n",
    ", 1.78539522e-14, 1.89461927e-14, 1.83714513e-14, 1.91272285e-14\n",
    ", 1.81790918e-14, 1.51935998e-14, 1.55331746e-14, 1.37627320e-14\n",
    ", 1.37333973e-14, 1.47261781e-14, 1.35323358e-14, 1.23234074e-14\n",
    ", 1.26296023e-14, 1.39794705e-14, 1.32391885e-14, 1.33172509e-14\n",
    ", 1.40752537e-14, 1.35291881e-14, 1.46771014e-14, 1.57039580e-14\n",
    ", 1.76870590e-14, 2.11409680e-14, 2.66470647e-14, 2.09066429e-14\n",
    ", 1.68226688e-14, 1.63034232e-14, 1.32317697e-14, 1.20372472e-14\n",
    ", 1.10395275e-14, 1.17336558e-14, 1.12817157e-14, 1.31068881e-14\n",
    ", 1.36940739e-14, 1.48016686e-14, 1.35999052e-14, 1.56644411e-14\n",
    ", 1.51726149e-14, 1.95274934e-14, 1.84669709e-14, 1.89443054e-14\n",
    ", 1.82544652e-14, 1.92617658e-14, 1.80902967e-14, 2.17239287e-14\n",
    ", 2.67917043e-14, 4.45194367e-14, 2.01857457e-12, 4.40594585e-12\n",
    ", 1.74602155e-12, 4.30562941e-14, 2.53461498e-14, 1.87278757e-14\n",
    ", 1.54232144e-14, 1.67924147e-14, 1.22749773e-14, 1.25017017e-14\n",
    ", 1.22475994e-14, 1.02921463e-14, 1.07700101e-14, 1.02658035e-14\n",
    ", 9.54949869e-15, 9.84280694e-15, 8.88745310e-15, 9.02206922e-15\n",
    ", 8.47210049e-15, 8.64491709e-15, 1.32254861e-14, 1.89573615e-14\n",
    ", 1.23079196e-14, 8.62994931e-15, 8.12535185e-15, 8.01035318e-15\n",
    ", 7.53220890e-15, 8.02056256e-15, 7.90231409e-15, 7.63270083e-15\n",
    ", 7.93212379e-15, 7.28368608e-15, 7.59772607e-15, 7.26136429e-15\n",
    ", 7.86504197e-15, 7.36256360e-15, 7.02847343e-15, 7.08620266e-15\n",
    ", 6.86068169e-15, 7.21792433e-15, 7.28674098e-15, 6.88181371e-15\n",
    ", 6.78751472e-15, 6.59002904e-15, 6.74850515e-15, 6.53743454e-15\n",
    ", 6.70834535e-15, 6.72520433e-15, 6.78371437e-15, 6.70420118e-15\n",
    ", 6.97442862e-15, 7.26767528e-15, 6.79388360e-15, 6.83101277e-15\n",
    ", 6.90684197e-15, 6.45716620e-15, 6.66190889e-15, 6.49304182e-15\n",
    ", 6.38068712e-15, 6.29160702e-15, 5.92354089e-15, 6.33890242e-15\n",
    ", 6.33787606e-15, 5.76688121e-15, 6.31821916e-15, 6.34536916e-15\n",
    ", 6.51250512e-15, 6.43164190e-15, 6.46530769e-15, 6.44724883e-15\n",
    ", 7.48305304e-15, 7.50925230e-15, 6.28419317e-15, 6.33908319e-15\n",
    ", 5.86954984e-15, 6.54561206e-15, 6.08872456e-15, 6.40874736e-15\n",
    ", 5.95870142e-15, 6.13488554e-15, 5.83721527e-15, 5.87793931e-15\n",
    ", 5.81207088e-15, 5.98748087e-15, 5.94551525e-15, 5.75415575e-15\n",
    ", 5.66968278e-15, 6.11006036e-15, 5.72066372e-15, 5.96629716e-15\n",
    ", 5.80372053e-15, 5.75583336e-15, 5.84628922e-15, 5.63642362e-15\n",
    ", 5.34942930e-15, 5.75920960e-15, 6.05337029e-15, 6.61372576e-15\n",
    ", 7.14210116e-15, 6.94968538e-15, 1.85742697e-14, 3.52090532e-14\n",
    ", 1.48785528e-14, 6.23577963e-15, 5.66229647e-15, 5.39212323e-15\n",
    ", 5.32890121e-15, 5.54967559e-15, 5.29485491e-15, 5.65665900e-15\n",
    ", 5.31337965e-15, 5.30139224e-15, 5.21434237e-15, 5.61739646e-15\n",
    ", 5.62673191e-15, 5.68441483e-15, 5.43332729e-15, 5.34563989e-15\n",
    ", 5.69510011e-15, 6.43038706e-15, 5.52069097e-15, 5.22891308e-15\n",
    ", 5.06513758e-15, 5.15715319e-15, 5.32484298e-15, 5.37071225e-15\n",
    ", 5.24099974e-15, 5.14413780e-15, 5.05322799e-15, 5.27277366e-15\n",
    ", 5.17209094e-15, 5.19895605e-15, 5.04662049e-15, 5.13492402e-15\n",
    ", 5.39573281e-15, 5.13639899e-15, 5.29696474e-15, 5.29749076e-15\n",
    ", 5.23187737e-15, 5.14179424e-15, 1.44011463e-14, 2.29753019e-14\n",
    ", 8.85041560e-15, 5.16398069e-15, 5.09075672e-15, 5.06681957e-15\n",
    ", 5.17284653e-15, 4.99688083e-15, 5.01988585e-15, 5.07952302e-15\n",
    ", 4.97188381e-15, 5.17733558e-15, 4.97124292e-15, 4.96910679e-15\n",
    ", 4.96283207e-15, 5.07193856e-15, 4.80712108e-15, 4.97630935e-15\n",
    ", 4.93727883e-15, 4.84091247e-15, 5.07370238e-15, 4.76459850e-15\n",
    ", 4.86678392e-15, 5.03907955e-15, 4.91645908e-15, 4.99691785e-15\n",
    ", 4.81326372e-15, 5.56398292e-15, 5.40286001e-15, 4.91762834e-15\n",
    ", 4.96042200e-15, 4.86125369e-15, 5.04306529e-15, 4.89229744e-15\n",
    ", 4.93924928e-15, 4.91889752e-15, 4.92336366e-15, 4.91476256e-15\n",
    ", 4.90731383e-15, 4.79751988e-15, 4.96181659e-15, 5.04353794e-15]\n",
    "\n",
    "#plot the data with ploty:\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "freqs = [i/2 for i in range(0, 280)]\n",
    "prominence_lvl_pos = 50\n",
    "prominence_pos=(max(one_psd) - min(one_psd)) / prominence_lvl_pos\n",
    "noisy_freqs_indexes, _ = find_peaks(one_psd, prominence=prominence_pos)\n",
    "noisy_freqs_indexes = [int(i) for i in noisy_freqs_indexes]\n",
    "\n",
    "for i in range(0,2):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=freqs, y=one_psd, name='psd'))\n",
    "    fig.update_layout(title=' PSD', xaxis_title='Frequency', yaxis_title='Amplitude',\n",
    "            yaxis = dict(\n",
    "            showexponent = 'all',\n",
    "            exponentformat = 'e'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[freqs[noisy_freqs_indexes[0]]], y=[one_psd[noisy_freqs_indexes[0]]], mode='markers', name='peaks'))\n",
    "\n",
    "    if i == 0:\n",
    "        fig.update_yaxes(type=\"log\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_head_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool('False')\n",
    "\n",
    "#convert \"false\" to boolean:\n",
    "import ast\n",
    "t = ast.literal_eval('False')\n",
    "t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne-qc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
